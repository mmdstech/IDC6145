{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmdstech/IDC6145/blob/main/assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2: Word Counting and Analysis of text\n"
      ],
      "metadata": {
        "id": "nZHxhrB6RSfM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and initialize"
      ],
      "metadata": {
        "id": "a0teY5ZOR2VF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nrf3m7auROVz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29ed801c-e881-47d3-c6b4-d7efef4d5c86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=cade70a39d9b6f269cdb7e781abbfa43eb030bf6bdee227b1a7be38f0269b3af\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a Spark Context\n",
        "sc = SparkSession.builder.master(\"local[*]\").appName(\"Test\").getOrCreate().sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Counting Task\n",
        "### Finish the following tasks\n",
        "1. Start from the provided text, create an RDD named `words` that contains all words in lower case for future use\n",
        "2. Use `words` RDD to generate a word counts list in the form of pairs like ``[('apple', 32), ('banana', 21), ... ]`` and store it in an RDD named `wordCounts`\n",
        "   - Refer to the example notebook in this module for demonstration\n",
        "   - You will be using `map`, `flatMap`, `reduceByKey` methods to achieve the goal\n",
        "\n",
        "**Hint**: Use the `take` method to show the first 10 records in both `words` and `wordCounts` RDD at the end of each task to show what you get"
      ],
      "metadata": {
        "id": "PgjM_3NNXAsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''word count from Wikipedia the free encyclopedia\n",
        "the word count is the number of words in a document or passage of text Word counting may be needed when a text\n",
        "is required to stay within certain numbers of words This may particularly be the case in academia legal\n",
        "proceedings journalism and advertising Word count is commonly used by translators to determine the price for\n",
        "the translation job Word counts may also be used to calculate measures of readability and to measure typing\n",
        "and reading speeds usually in words per minute When converting character counts to words a measure of five or\n",
        "six characters to a word is generally used Contents Details and variations of definition Software In fiction\n",
        "In non fiction See also References Sources External links Details and variations of definition\n",
        "This section does not cite any references or sources Please help improve this section by adding citations to\n",
        "reliable sources Unsourced material may be challenged and removed\n",
        "Variations in the operational definitions of how to count the words can occur namely what counts as a word and\n",
        "which words don't count toward the total However especially since the advent of widespread word processing there\n",
        "is a broad consensus on these operational definitions and hence the bottom line integer result\n",
        "The consensus is to accept the text segmentation rules generally found in most word processing software including how\n",
        "word boundaries are determined which depends on how word dividers are defined The first trait of that definition is that a space any of various whitespace\n",
        "characters such as a regular word space an em space or a tab character is a word divider Usually a hyphen or a slash is too\n",
        "Different word counting programs may give varying results depending on the text segmentation rule\n",
        "details and on whether words outside the main text such as footnotes endnotes or hidden text) are counted But the behavior\n",
        "of most major word processing applications is broadly similar However during the era when school assignments were done in\n",
        "handwriting or with typewriters the rules for these definitions often differed from todays consensus\n",
        "Most importantly many students were drilled on the rule that certain words don't count usually articles namely a an the but\n",
        "sometimes also others such as conjunctions for example and or but and some prepositions usually to of Hyphenated permanent\n",
        "compounds such as follow up noun or long term adjective were counted as one word To save the time and effort of counting\n",
        "word by word often a rule of thumb for the average number of words per line was used such as 10 words per line These rules\n",
        "have fallen by the wayside in the word processing era the word count feature of such software which follows the text\n",
        "segmentation rules mentioned earlier is now the standard arbiter because it is largely consistent across documents and\n",
        "applications and because it is fast effortless and costless already included with the application As for which sections of\n",
        "a document count toward the total such as footnotes endnotes abstracts reference lists and bibliographies tables figure\n",
        "captions hidden text the person in charge teacher client can define their choice and users students workers can simply\n",
        "select or exclude the elements accordingly and watch the word count automatically update Software Modern web browsers\n",
        "support word counting via extensions via a JavaScript bookmarklet or a script that is hosted in a website Most word\n",
        "processors can also count words Unix like systems include a program wc specifically for word counting\n",
        "As explained earlier different word counting programs may give varying results depending on the text segmentation rule\n",
        "details The exact number of words often is not a strict requirement thus the variation is acceptable\n",
        "In fiction Novelist Jane Smiley suggests that length is an important quality of the novel However novels can vary\n",
        "tremendously in length Smiley lists novels as typically being between and words while National Novel Writing Month\n",
        "requires its novels to be at least words There are no firm rules for example the boundary between a novella and a novel\n",
        "is arbitrary and a literary work may be difficult to categorise But while the length of a novel is to a large extent up\n",
        "to its writer lengths may also vary by subgenre many chapter books for children start at a length of about words and a\n",
        "typical mystery novel might be in the to word range while a thriller could be over words\n",
        "The Science Fiction and Fantasy Writers of America specifies word lengths for each category of its Nebula award categories\n",
        "Classification\tWord count Novel over words Novella to words Novelette to words Short story under words\n",
        "In non fiction The acceptable length of an academic dissertation varies greatly dependent predominantly on the subject\n",
        "Numerous American universities limit Ph.D. dissertations to at most words barring special permission for exceeding this limit\n",
        "'''"
      ],
      "metadata": {
        "id": "ruoMO8DMXq53"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here for task 1\n",
        "lines = sc.parallelize(text.split('\\n'))\n",
        "words = lines.flatMap(lambda line: line.split()).map(lambda word: word.lower())\n",
        "\n",
        "print(\"\\nfirst 10 collection of words, flattened:\")\n",
        "print(words.take(10))\n",
        "\n",
        "# Example output: ['word', 'count', 'from', 'wikipedia', 'the', 'free', 'encyclopedia', 'the', 'word', 'count']\n"
      ],
      "metadata": {
        "id": "ddmdQGYcqhjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e58b0e0-373b-4ebd-d46d-0682eec86ace"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "first 10 collection of words, flattened:\n",
            "['word', 'count', 'from', 'wikipedia', 'the', 'free', 'encyclopedia', 'the', 'word', 'count']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here for task 2\n",
        "wordCounts = words.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
        "print('\\nfirst 10 collection of pairs')\n",
        "print(wordCounts.take(10))\n",
        "\n",
        "# Example output: [('count', 11), ('wikipedia', 1), ('free', 1), ('is', 19), ('of', 25), ('in', 15), ('counting', 6), ('may', 8), ('needed', 1), ('when', 3)]"
      ],
      "metadata": {
        "id": "jcOYxSFwsPx1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9deff01-499a-4561-fa91-ceaa10d074ff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "first 10 collection of pairs\n",
            "[('count', 11), ('wikipedia', 1), ('free', 1), ('is', 19), ('of', 25), ('in', 15), ('counting', 6), ('may', 8), ('needed', 1), ('when', 3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Use the `words` and `wordCounts` RDD\n",
        "\n",
        "   A. Calculate the average length of words in the `words` RDD\n",
        "\n",
        "   B. Find the top 5 longest words\n",
        "   \n",
        "   C. Find the top 5 words with the highest counts\n",
        "\n",
        "Sample run:\n",
        "```\n",
        "Avg length: 5.076543209876541\n",
        "Top longest words: ['bibliographies', 'classification', 'automatically', 'predominantly', 'dissertations']\n",
        "Top frequent words: [('the', 43), ('word', 28), ('a', 28), ('of', 25), ('and', 23)]\n",
        "```"
      ],
      "metadata": {
        "id": "X9o9VCA-p0PF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here for task 3\n",
        "wordLengths = words.map(lambda word: len(word))\n",
        "totalLength = wordLengths.reduce(lambda a, b: a + b)\n",
        "wordCount = words.count()\n",
        "\n",
        "averageLength = totalLength / wordCount\n",
        "print(f\"Average length: {averageLength}\")\n",
        "\n",
        "longestWords = (\n",
        "    words.map(lambda word: (word, len(word)))\n",
        "      .sortBy(lambda x: x[1], ascending=False)\n",
        "      .map(lambda y: y[0])\n",
        "      .take(5)\n",
        ")\n",
        "# top5LongestWords = longestWords.map(lambda x: x[0]).take(5)\n",
        "print(f\"Top longest words: {longestWords}\")\n",
        "\n",
        "top5WordsByCount = wordCounts.sortBy(lambda x: x[1], ascending=False).take(5)\n",
        "print(f\"Top frequent words: {top5WordsByCount}\")\n"
      ],
      "metadata": {
        "id": "xRltD5ASsI-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8379e311-edd8-4918-d51f-0726b7d8a5eb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average length: 5.076543209876543\n",
            "Top longest words: ['bibliographies', 'classification', 'automatically', 'predominantly', 'dissertations']\n",
            "Top frequent words: [('the', 43), ('word', 28), ('a', 28), ('of', 25), ('and', 23)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission\n",
        "\n",
        "1. After you have finished you code, run and get the correct output.\n",
        "2. Print the page as PDF and upload the PDF file to Canvas"
      ],
      "metadata": {
        "id": "Cc_jcYPXs-lg"
      }
    }
  ]
}